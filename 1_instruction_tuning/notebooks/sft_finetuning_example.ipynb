{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning with SFTTrainer\n",
    "\n",
    "This notebook demonstrates how to fine-tune the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer` from the `trl` library. The notebook cells run and will finetune the model. You can select your difficulty by trying out different datasets.\n",
    "\n",
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Exercise: Fine-Tuning SmolLM2 with SFTTrainer</h2>\n",
    "    <p>Take a dataset from the Hugging Face hub and finetune a model on it. </p> \n",
    "    <p><b>Difficulty Levels</b></p>\n",
    "    <p>üê¢ Use the `HuggingFaceTB/smoltalk` dataset</p>\n",
    "    <p>üêï Try out the `bigcode/the-stack-smol` dataset and finetune a code generation model on a specific subset `data/python`.</p>\n",
    "    <p>ü¶Å Select a dataset that relates to a real world use case your interested in</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_PROJECT: smol-course-smehmood\n",
      "WANDB_LOG_MODEL: checkpoint\n",
      "BLARGH: None\n"
     ]
    }
   ],
   "source": [
    "# Install the requirements in Google Colab\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Authenticate to Hugging Face\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print(f\"WANDB_PROJECT: {os.getenv('WANDB_PROJECT')}\")\n",
    "print(f\"WANDB_LOG_MODEL: {os.getenv('WANDB_LOG_MODEL')}\")\n",
    "print(f\"BLARGH: {os.getenv('BLARGH')}\")\n",
    "\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "\n",
    "\n",
    "# for convenience you can create an environment variable containing your hub token as HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer, setup_chat_format\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Set up the chat format\n",
    "model, tokenizer = setup_chat_format(model=base_model, tokenizer=tokenizer)\n",
    "\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"SmolLM2-FT-smehmood\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate with the base model\n",
    "\n",
    "Here we will try out the base model which does not have a chat template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "user\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a haiku about programming\n",
      "Write a\n"
     ]
    }
   ],
   "source": [
    "# Let's test the base model before training\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"Before training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n",
    "\n",
    "We will load a sample dataset and format it for training. The dataset should be structured with input-output pairs, where each input is a prompt and the output is the expected response from the model.\n",
    "\n",
    "**TRL will format input messages based on the model's chat templates.** They need to be represented as a list of dictionaries with the keys: `role` and `content`,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Load a sample dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: define your dataset and config using the path and name parameters\n",
    "ds = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ü¶Å If your dataset is not in a format that TRL can convert to the chat template, you will need to process it. Refer to the [module](../chat_templates.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the SFTTrainer\n",
    "\n",
    "The `SFTTrainer` is configured with various parameters that control the training process. These include the number of training steps, batch size, learning rate, and evaluation strategy. Adjust these parameters based on your specific requirements and computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SFTConfig.__init__() got an unexpected keyword argument 'eval_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configure the SFTTrainer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sft_config \u001b[38;5;241m=\u001b[39m \u001b[43mSFTConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./sft_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Adjust based on dataset size and desired training duration\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set according to your GPU memory capacity\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Common starting point for fine-tuning\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Frequency of logging training metrics\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Frequency of saving model checkpoints\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Evaluate the model at regular intervals\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Frequency of evaluation\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_mps_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use MPS for mixed precision training\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhub_model_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set a unique name for your model\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize the SFTTrainer\u001b[39;00m\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[1;32m     22\u001b[0m     args\u001b[38;5;241m=\u001b[39msft_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: SFTConfig.__init__() got an unexpected keyword argument 'eval_dataset'"
     ]
    }
   ],
   "source": [
    "# Configure the SFTTrainer\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"./sft_output\",\n",
    "    max_steps=1000,  # Adjust based on dataset size and desired training duration\n",
    "    per_device_train_batch_size=4,  # Set according to your GPU memory capacity\n",
    "    learning_rate=5e-5,  # Common starting point for fine-tuning\n",
    "    logging_steps=10,  # Frequency of logging training metrics\n",
    "    save_steps=100,  # Frequency of saving model checkpoints\n",
    "    evaluation_strategy=\"steps\",  # Evaluate the model at regular intervals\n",
    "    eval_steps=50,  # Frequency of evaluation\n",
    "    use_mps_device=(\n",
    "        True if device == \"mps\" else False\n",
    "    ),  # Use MPS for mixed precision training\n",
    "    hub_model_id=finetune_name,  # Set a unique name for your model\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Initialize the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    args=sft_config,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=ds[\"test\"],\n",
    ")\n",
    "\n",
    "# TODO: ü¶Å üêï align the SFTTrainer params with your chosen dataset. For example, if you are using the `bigcode/the-stack-smol` dataset, you will need to choose the `content` column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "With the trainer configured, we can now proceed to train the model. The training process will involve iterating over the dataset, computing the loss, and updating the model's parameters to minimize this loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3652b0f4b8584070a0587fd4f7bfdb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3413, 'grad_norm': 1.4055887460708618, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.02}\n",
      "{'loss': 0.3388, 'grad_norm': 1.4032888412475586, 'learning_rate': 4.9e-05, 'epoch': 0.04}\n",
      "{'loss': 0.3744, 'grad_norm': 2.010791063308716, 'learning_rate': 4.85e-05, 'epoch': 0.05}\n",
      "{'loss': 0.3675, 'grad_norm': 2.2714316844940186, 'learning_rate': 4.8e-05, 'epoch': 0.07}\n",
      "{'loss': 0.354, 'grad_norm': 1.6922193765640259, 'learning_rate': 4.75e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a915c0377de48af9497589f59dbc9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2041603326797485, 'eval_runtime': 3.3033, 'eval_samples_per_second': 36.024, 'eval_steps_per_second': 4.541, 'epoch': 0.09}\n",
      "{'loss': 0.3844, 'grad_norm': 1.684668779373169, 'learning_rate': 4.7e-05, 'epoch': 0.11}\n",
      "{'loss': 0.4101, 'grad_norm': 1.7317347526550293, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.12}\n",
      "{'loss': 0.3781, 'grad_norm': 1.6600823402404785, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.14}\n",
      "{'loss': 0.3568, 'grad_norm': 1.9436765909194946, 'learning_rate': 4.55e-05, 'epoch': 0.16}\n",
      "{'loss': 0.3513, 'grad_norm': 1.9780144691467285, 'learning_rate': 4.5e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542c8014b2dd413388e617b852b49dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2328718900680542, 'eval_runtime': 3.4331, 'eval_samples_per_second': 34.662, 'eval_steps_per_second': 4.369, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-100)... Done. 1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3586, 'grad_norm': 1.7254440784454346, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.19}\n",
      "{'loss': 0.4062, 'grad_norm': 1.9568184614181519, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.21}\n",
      "{'loss': 0.3961, 'grad_norm': 1.7815574407577515, 'learning_rate': 4.35e-05, 'epoch': 0.23}\n",
      "{'loss': 0.3825, 'grad_norm': 2.057816743850708, 'learning_rate': 4.3e-05, 'epoch': 0.25}\n",
      "{'loss': 0.4062, 'grad_norm': 2.050762414932251, 'learning_rate': 4.25e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc391c542e44df198b54db30ec732c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2358105182647705, 'eval_runtime': 3.6361, 'eval_samples_per_second': 32.727, 'eval_steps_per_second': 4.125, 'epoch': 0.27}\n",
      "{'loss': 0.3862, 'grad_norm': 1.9156574010849, 'learning_rate': 4.2e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4155, 'grad_norm': 1.8134719133377075, 'learning_rate': 4.15e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4163, 'grad_norm': 1.6427106857299805, 'learning_rate': 4.1e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4193, 'grad_norm': 1.6502608060836792, 'learning_rate': 4.05e-05, 'epoch': 0.34}\n",
      "{'loss': 0.4175, 'grad_norm': 1.7752454280853271, 'learning_rate': 4e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e71133b5ee494f86be0e69f8bd1859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2107208967208862, 'eval_runtime': 4.2434, 'eval_samples_per_second': 28.043, 'eval_steps_per_second': 3.535, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-200)... Done. 1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4362, 'grad_norm': 1.570641040802002, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.37}\n",
      "{'loss': 0.4556, 'grad_norm': 1.8195549249649048, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.39}\n",
      "{'loss': 0.4443, 'grad_norm': 1.95530366897583, 'learning_rate': 3.85e-05, 'epoch': 0.41}\n",
      "{'loss': 0.4085, 'grad_norm': 1.5904784202575684, 'learning_rate': 3.8e-05, 'epoch': 0.42}\n",
      "{'loss': 0.4216, 'grad_norm': 1.689742922782898, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41983529077b4f15bd1549055c1cf7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.207082748413086, 'eval_runtime': 4.3954, 'eval_samples_per_second': 27.074, 'eval_steps_per_second': 3.413, 'epoch': 0.44}\n",
      "{'loss': 0.4465, 'grad_norm': 1.5418603420257568, 'learning_rate': 3.7e-05, 'epoch': 0.46}\n",
      "{'loss': 0.4227, 'grad_norm': 1.6429516077041626, 'learning_rate': 3.65e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4552, 'grad_norm': 1.9243789911270142, 'learning_rate': 3.6e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4537, 'grad_norm': 1.7221508026123047, 'learning_rate': 3.55e-05, 'epoch': 0.51}\n",
      "{'loss': 0.417, 'grad_norm': 1.5729854106903076, 'learning_rate': 3.5e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547c836a3b0942e0a8c75c055f6cbea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1989201307296753, 'eval_runtime': 4.6319, 'eval_samples_per_second': 25.691, 'eval_steps_per_second': 3.238, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-300)... Done. 2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6296, 'grad_norm': 2.473332166671753, 'learning_rate': 3.45e-05, 'epoch': 0.55}\n",
      "{'loss': 0.63, 'grad_norm': 2.0301153659820557, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.57}\n",
      "{'loss': 0.6882, 'grad_norm': 2.112170457839966, 'learning_rate': 3.35e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6689, 'grad_norm': 1.987504005432129, 'learning_rate': 3.3e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6199, 'grad_norm': 2.0169382095336914, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61ae84cb3e44bd5b4f912068b6781e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.112380862236023, 'eval_runtime': 5.8816, 'eval_samples_per_second': 20.232, 'eval_steps_per_second': 2.55, 'epoch': 0.62}\n",
      "{'loss': 0.6767, 'grad_norm': 1.8831928968429565, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.64}\n",
      "{'loss': 0.6572, 'grad_norm': 2.395826816558838, 'learning_rate': 3.15e-05, 'epoch': 0.65}\n",
      "{'loss': 0.6575, 'grad_norm': 2.355778455734253, 'learning_rate': 3.1e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6491, 'grad_norm': 1.515273094177246, 'learning_rate': 3.05e-05, 'epoch': 0.69}\n",
      "{'loss': 0.6394, 'grad_norm': 1.9771174192428589, 'learning_rate': 3e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5f53882baf4a2c8d89dea47d576ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1037814617156982, 'eval_runtime': 5.7204, 'eval_samples_per_second': 20.803, 'eval_steps_per_second': 2.622, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-400)... Done. 1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6682, 'grad_norm': 1.8693009614944458, 'learning_rate': 2.95e-05, 'epoch': 0.73}\n",
      "{'loss': 0.6447, 'grad_norm': 2.0201141834259033, 'learning_rate': 2.9e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7273, 'grad_norm': 2.097691535949707, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.76}\n",
      "{'loss': 0.719, 'grad_norm': 2.215272903442383, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.78}\n",
      "{'loss': 0.6898, 'grad_norm': 1.8564989566802979, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef70eefa35cd4c4981c2f7741292ce83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.086350440979004, 'eval_runtime': 4.6117, 'eval_samples_per_second': 25.804, 'eval_steps_per_second': 3.253, 'epoch': 0.8}\n",
      "{'loss': 0.7123, 'grad_norm': 2.140727996826172, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.81}\n",
      "{'loss': 0.6596, 'grad_norm': 1.9380744695663452, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.83}\n",
      "{'loss': 0.7462, 'grad_norm': 2.165121555328369, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7469, 'grad_norm': 1.9246670007705688, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.87}\n",
      "{'loss': 0.7775, 'grad_norm': 2.2277355194091797, 'learning_rate': 2.5e-05, 'epoch': 0.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f389a2d616a74f5c820a09c942b06c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0707924365997314, 'eval_runtime': 4.695, 'eval_samples_per_second': 25.346, 'eval_steps_per_second': 3.195, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-500)... Done. 2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7001, 'grad_norm': 2.0118863582611084, 'learning_rate': 2.45e-05, 'epoch': 0.9}\n",
      "{'loss': 0.7283, 'grad_norm': 2.1070821285247803, 'learning_rate': 2.4e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7204, 'grad_norm': 1.9174699783325195, 'learning_rate': 2.35e-05, 'epoch': 0.94}\n",
      "{'loss': 0.7508, 'grad_norm': 1.9481037855148315, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.96}\n",
      "{'loss': 0.6947, 'grad_norm': 1.8347644805908203, 'learning_rate': 2.25e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaec3416eb8c4ecfa605c066d9818515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0643949508666992, 'eval_runtime': 3.6841, 'eval_samples_per_second': 32.301, 'eval_steps_per_second': 4.072, 'epoch': 0.97}\n",
      "{'loss': 0.7061, 'grad_norm': 1.8546468019485474, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.99}\n",
      "{'loss': 0.5141, 'grad_norm': 1.8330382108688354, 'learning_rate': 2.15e-05, 'epoch': 1.01}\n",
      "{'loss': 0.3539, 'grad_norm': 1.6955584287643433, 'learning_rate': 2.1e-05, 'epoch': 1.03}\n",
      "{'loss': 0.2982, 'grad_norm': 1.29619300365448, 'learning_rate': 2.05e-05, 'epoch': 1.04}\n",
      "{'loss': 0.348, 'grad_norm': 1.3292242288589478, 'learning_rate': 2e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54b3437018f49d99c2801eff3285dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.163774013519287, 'eval_runtime': 3.3734, 'eval_samples_per_second': 35.276, 'eval_steps_per_second': 4.447, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-600)... Done. 2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.369, 'grad_norm': 1.7255553007125854, 'learning_rate': 1.9500000000000003e-05, 'epoch': 1.08}\n",
      "{'loss': 0.3543, 'grad_norm': 1.425973892211914, 'learning_rate': 1.9e-05, 'epoch': 1.1}\n",
      "{'loss': 0.3704, 'grad_norm': 1.4451457262039185, 'learning_rate': 1.85e-05, 'epoch': 1.12}\n",
      "{'loss': 0.3394, 'grad_norm': 1.5592951774597168, 'learning_rate': 1.8e-05, 'epoch': 1.13}\n",
      "{'loss': 0.3467, 'grad_norm': 1.6123753786087036, 'learning_rate': 1.75e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877f8bfff4fb457492d566b31305cfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1880748271942139, 'eval_runtime': 3.5639, 'eval_samples_per_second': 33.39, 'eval_steps_per_second': 4.209, 'epoch': 1.15}\n",
      "{'loss': 0.4052, 'grad_norm': 1.8689258098602295, 'learning_rate': 1.7000000000000003e-05, 'epoch': 1.17}\n",
      "{'loss': 0.3674, 'grad_norm': 1.8417631387710571, 'learning_rate': 1.65e-05, 'epoch': 1.19}\n",
      "{'loss': 0.365, 'grad_norm': 1.8094602823257446, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.2}\n",
      "{'loss': 0.4028, 'grad_norm': 2.1250414848327637, 'learning_rate': 1.55e-05, 'epoch': 1.22}\n",
      "{'loss': 0.3479, 'grad_norm': 1.7461907863616943, 'learning_rate': 1.5e-05, 'epoch': 1.24}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b895584c7e4ed7817c490d2bc32d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1838161945343018, 'eval_runtime': 3.653, 'eval_samples_per_second': 32.576, 'eval_steps_per_second': 4.106, 'epoch': 1.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-700)... Done. 1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3677, 'grad_norm': 1.8036075830459595, 'learning_rate': 1.45e-05, 'epoch': 1.26}\n",
      "{'loss': 0.4126, 'grad_norm': 1.5294831991195679, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.27}\n",
      "{'loss': 0.3986, 'grad_norm': 1.5314240455627441, 'learning_rate': 1.3500000000000001e-05, 'epoch': 1.29}\n",
      "{'loss': 0.3656, 'grad_norm': 1.659386396408081, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.31}\n",
      "{'loss': 0.413, 'grad_norm': 2.2836437225341797, 'learning_rate': 1.25e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdbe25ec0a2428989e79729fb80f05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1909675598144531, 'eval_runtime': 3.4979, 'eval_samples_per_second': 34.02, 'eval_steps_per_second': 4.288, 'epoch': 1.33}\n",
      "{'loss': 0.3552, 'grad_norm': 1.6762443780899048, 'learning_rate': 1.2e-05, 'epoch': 1.35}\n",
      "{'loss': 0.3947, 'grad_norm': 1.786506175994873, 'learning_rate': 1.1500000000000002e-05, 'epoch': 1.36}\n",
      "{'loss': 0.3748, 'grad_norm': 1.8963664770126343, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.38}\n",
      "{'loss': 0.3997, 'grad_norm': 2.061994791030884, 'learning_rate': 1.05e-05, 'epoch': 1.4}\n",
      "{'loss': 0.3964, 'grad_norm': 2.105773448944092, 'learning_rate': 1e-05, 'epoch': 1.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42134654ff941df9714d2f038f6e172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1959233283996582, 'eval_runtime': 3.4242, 'eval_samples_per_second': 34.752, 'eval_steps_per_second': 4.381, 'epoch': 1.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-800)... Done. 1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3938, 'grad_norm': 1.8047404289245605, 'learning_rate': 9.5e-06, 'epoch': 1.43}\n",
      "{'loss': 0.3943, 'grad_norm': 1.705028772354126, 'learning_rate': 9e-06, 'epoch': 1.45}\n",
      "{'loss': 0.3833, 'grad_norm': 1.8101732730865479, 'learning_rate': 8.500000000000002e-06, 'epoch': 1.47}\n",
      "{'loss': 0.4209, 'grad_norm': 1.852452278137207, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.49}\n",
      "{'loss': 0.3981, 'grad_norm': 1.6988362073898315, 'learning_rate': 7.5e-06, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645e459367b2446299ca78fcca9ca581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1871147155761719, 'eval_runtime': 3.5509, 'eval_samples_per_second': 33.513, 'eval_steps_per_second': 4.224, 'epoch': 1.5}\n",
      "{'loss': 0.3885, 'grad_norm': 2.1801981925964355, 'learning_rate': 7.000000000000001e-06, 'epoch': 1.52}\n",
      "{'loss': 0.3518, 'grad_norm': 1.7837287187576294, 'learning_rate': 6.5000000000000004e-06, 'epoch': 1.54}\n",
      "{'loss': 0.425, 'grad_norm': 1.6383435726165771, 'learning_rate': 6e-06, 'epoch': 1.56}\n",
      "{'loss': 0.403, 'grad_norm': 1.7306358814239502, 'learning_rate': 5.500000000000001e-06, 'epoch': 1.58}\n",
      "{'loss': 0.4314, 'grad_norm': 2.089479923248291, 'learning_rate': 5e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb94c5d5bdf34e2c9011721e88d44301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1861331462860107, 'eval_runtime': 4.1753, 'eval_samples_per_second': 28.501, 'eval_steps_per_second': 3.593, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-900)... Done. 1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4093, 'grad_norm': 2.1691319942474365, 'learning_rate': 4.5e-06, 'epoch': 1.61}\n",
      "{'loss': 0.4117, 'grad_norm': 1.3630386590957642, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.63}\n",
      "{'loss': 0.4022, 'grad_norm': 1.6978490352630615, 'learning_rate': 3.5000000000000004e-06, 'epoch': 1.65}\n",
      "{'loss': 0.3836, 'grad_norm': 1.9573407173156738, 'learning_rate': 3e-06, 'epoch': 1.66}\n",
      "{'loss': 0.4451, 'grad_norm': 1.8079036474227905, 'learning_rate': 2.5e-06, 'epoch': 1.68}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee082e2a79694fc68c986bcff48265ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1851311922073364, 'eval_runtime': 4.1313, 'eval_samples_per_second': 28.805, 'eval_steps_per_second': 3.631, 'epoch': 1.68}\n",
      "{'loss': 0.4248, 'grad_norm': 1.9778358936309814, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.7}\n",
      "{'loss': 0.4155, 'grad_norm': 1.7592504024505615, 'learning_rate': 1.5e-06, 'epoch': 1.72}\n",
      "{'loss': 0.4014, 'grad_norm': 1.9902540445327759, 'learning_rate': 1.0000000000000002e-06, 'epoch': 1.73}\n",
      "{'loss': 0.3812, 'grad_norm': 1.4668457508087158, 'learning_rate': 5.000000000000001e-07, 'epoch': 1.75}\n",
      "{'loss': 0.3121, 'grad_norm': 1.5213855504989624, 'learning_rate': 0.0, 'epoch': 1.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23e3f0048864942b203a65c9f70ee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1856260299682617, 'eval_runtime': 4.4145, 'eval_samples_per_second': 26.956, 'eval_steps_per_second': 3.398, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./sft_output/checkpoint-1000)... Done. 2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 508.5676, 'train_samples_per_second': 7.865, 'train_steps_per_second': 1.966, 'train_loss': 0.4696823668479919, 'epoch': 1.77}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You have set `args.eval_strategy` to IntervalStrategy.STEPS but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinetune_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/trainer.py:2635\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2632\u001b[0m             logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeleting older checkpoint [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] due to args.save_total_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2633\u001b[0m             shutil\u001b[38;5;241m.\u001b[39mrmtree(checkpoint, ignore_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;66;03m# Wait for the checkpoint to be uploaded.\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/trainer_callback.py:471\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_end\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/trainer_callback.py:518\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 518\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:919\u001b[0m, in \u001b[0;36mWandbCallback.on_train_end\u001b[0;34m(self, args, state, control, model, tokenizer, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_model\u001b[38;5;241m.\u001b[39mis_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialized \u001b[38;5;129;01mand\u001b[39;00m state\u001b[38;5;241m.\u001b[39mis_world_process_zero:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m--> 919\u001b[0m     fake_trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[1;32m    921\u001b[0m         fake_trainer\u001b[38;5;241m.\u001b[39msave_model(temp_dir)\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/trainer.py:418\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    413\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `batch_eval_metrics`, your `compute_metrics` function must take a `compute_result`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m boolean argument which will be triggered after the last batch of the eval set to signal that the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m summary statistics should be returned by the function.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_strategy \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have set `args.eval_strategy` to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39meval_strategy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but you didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m     )\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_func \u001b[38;5;241m=\u001b[39m compute_loss_func\n",
      "\u001b[0;31mValueError\u001b[0m: You have set `args.eval_strategy` to IntervalStrategy.STEPS but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`. "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(f\"./{finetune_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinetune_tags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/transformers/trainer.py:4658\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m   4655\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model_tag \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   4656\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(model_tag)\n\u001b[0;32m-> 4658\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_card\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4660\u001b[0m \u001b[38;5;66;03m# Wait for the current upload to be finished.\u001b[39;00m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n",
      "File \u001b[0;32m~/src/smol-course/.venv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:637\u001b[0m, in \u001b[0;36mSFTTrainer.create_model_card\u001b[0;34m(self, model_name, dataset_name, tags)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth_version\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    629\u001b[0m     tags\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    631\u001b[0m model_card \u001b[38;5;241m=\u001b[39m generate_model_card(\n\u001b[1;32m    632\u001b[0m     base_model\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[1;32m    633\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m    634\u001b[0m     hub_model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id,\n\u001b[1;32m    635\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mdataset_name,\n\u001b[1;32m    636\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m--> 637\u001b[0m     wandb_url\u001b[38;5;241m=\u001b[39mwandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mget_url() \u001b[38;5;28;01mif\u001b[39;00m is_wandb_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    638\u001b[0m     trainer_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSFT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    639\u001b[0m )\n\u001b[1;32m    641\u001b[0m model_card\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: lightblue; padding: 10px; border-radius: 5px; margin-bottom: 20px; color:black'>\n",
    "    <h2 style='margin: 0;color:blue'>Bonus Exercise: Generate with fine-tuned model</h2>\n",
    "    <p>üêï Use the fine-tuned to model generate a response, just like with the base example..</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "user\n",
      "Write a haiku about programming\n",
      "assistant\n",
      "I'm a language model, I'm a language model, I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model. I'm a language model.\n"
     ]
    }
   ],
   "source": [
    "# Test the fine-tuned model on the same prompt\n",
    "\n",
    "# Let's test the base model before training\n",
    "prompt = \"Write a haiku about programming\"\n",
    "\n",
    "# Format with template\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "fine_tuned_model = AutoModelForCausalLM.from_pretrained(f\"./sft_output\").to(device)\n",
    "outputs = fine_tuned_model.generate(**inputs, max_new_tokens=100)\n",
    "print(\"After training:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíê You're done!\n",
    "\n",
    "This notebook provided a step-by-step guide to fine-tuning the `HuggingFaceTB/SmolLM2-135M` model using the `SFTTrainer`. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
    "\n",
    "- Try this notebook on a harder difficulty\n",
    "- Review a colleagues PR\n",
    "- Improve the course material via an Issue or PR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
